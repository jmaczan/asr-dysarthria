<div align="center">

# ðŸ˜º ASR Dysarthria

<a href="https://pytorch.org/get-started/locally/"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white"></a>
<a href="https://pytorchlightning.ai/"><img alt="Lightning" src="https://img.shields.io/badge/-Lightning-792ee5?logo=pytorchlightning&logoColor=white"></a>
<a href="https://hydra.cc/"><img alt="Config: Hydra" src="https://img.shields.io/badge/Config-Hydra-89b8cd"></a>
<a href="https://github.com/ashleve/lightning-hydra-template"><img alt="Template" src="https://img.shields.io/badge/-Lightning--Hydra--Template-017F2F?style=flat&logo=github&labelColor=gray"></a><br>

<!-- [![Paper](http://img.shields.io/badge/paper-arxiv.1001.2234-B31B1B.svg)](https://www.nature.com/articles/nature14539)
[![Conference](http://img.shields.io/badge/AnyConference-year-4b44ce.svg)](https://papers.nips.cc/paper/2020)
-->
</div>

## Description

Automatic speech recognition for people with dysarthria

Model is hosted on Hugging Face: https://huggingface.co/jmaczan/asr-dysarthria-wav2vec2-v0

## Installation

#### Pip

```bash
# clone project
git clone https://github.com/jmaczan/asr-dysarthria
cd asr-dysarthria

# [OPTIONAL] create conda environment
conda create -n asr-dysarthria python=3.9
conda activate asr-dysarthria

# install pytorch according to instructions
# https://pytorch.org/get-started/

# install requirements
pip install -r requirements.txt
```

#### Conda

```bash
# clone project
git clone https://github.com/jmaczan/asr-dysarthria
cd asr-dysarthria

# create conda environment and install dependencies
conda env create -f environment.yaml -n asr-dysarthria

# activate conda environment
conda activate asr-dysarthria
```

## How to run

Train model with default configuration

```bash
# train on CPU
python src/train.py trainer=cpu

# train on GPU
python src/train.py trainer=gpu
```

Train model with chosen experiment configuration from [configs/experiment/](configs/experiment/)

```bash
python src/train.py experiment=experiment_name.yaml
```

You can override any parameter from command line like this

```bash
python src/train.py trainer.max_epochs=20 data.batch_size=64
```

## Building the TORGO dataset

Run `python oldies/src/torgo_dataset_builder.py`

http://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html

Dataset is hosted on Hugging Face: https://huggingface.co/datasets/jmaczan/TORGO

## Open questions

- How to do audio data augmentation for TORGO dataset?
- How to obtain Nemours database of dysarthric speech? https://ieeexplore.ieee.org/document/608020

## Resources

### Papers

https://ar5iv.labs.arxiv.org/html/2204.00770 (https://arxiv.org/abs/2204.00770)

https://www.isca-speech.org/archive/pdfs/interspeech_2022/baskar22b_interspeech.pdf

https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10225595

https://www.sciencedirect.com/science/article/pii/S2405959521000874

https://www.isca-speech.org/archive/pdfs/interspeech_2021/green21_interspeech.pdf

https://arxiv.org/pdf/2006.11477.pdf

https://arxiv.org/pdf/2211.00089.pdf

https://www.sciencedirect.com/science/article/abs/pii/S0957417423002981

### Code

https://huggingface.co/blog/fine-tune-wav2vec2-english

### Data

http://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html

### Dataset

#### Big

https://huggingface.co/datasets/jmaczan/TORGO

#### Small

https://huggingface.co/datasets/jmaczan/TORGO-very-small

### Others

https://ai.meta.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/

https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html

https://huggingface.co/docs/datasets/v2.16.1/audio_dataset

https://distill.pub/2017/ctc/

https://ai.meta.com/blog/self-supervision-and-building-more-robust-speech-recognition-systems/

## License

MIT License

## Author

Made in [KaszÃ«bÃ«](https://en.wikipedia.org/wiki/Kashubia), [Poland ðŸ‡µðŸ‡±](https://en.wikipedia.org/wiki/Poland) by [JÄ™drzej PaweÅ‚ Maczan](https://maczan.pl), [on the shoulders of giants](https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants) in 2024
